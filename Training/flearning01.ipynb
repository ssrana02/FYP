{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CODE SEGMENTS FOR CONNECTING FRONEND TO BACKEND SERVER (FLASK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/')\n",
    "def home():\n",
    "    return 'Hello, World! This is your Flask application.'\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from trained_model import isolation_forest  # Import the trained model\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Endpoint to handle URL requests\n",
    "@app.route('/detect-malicious-url', methods=['POST'])\n",
    "def detect_malicious_url():\n",
    "    # Get URL from request\n",
    "    url = request.json.get('url')\n",
    "\n",
    "    # Preprocess URL and extract features\n",
    "    features = extract_features(url)\n",
    "\n",
    "    # Predict using the ML model\n",
    "    is_anomaly = isolation_forest.predict([features])[0]\n",
    "\n",
    "    # Store output in a database (Assuming a SQLite database for demonstration)\n",
    "    store_in_database(url, is_anomaly)\n",
    "\n",
    "    # Return result to front-end\n",
    "    return jsonify({'is_malicious': bool(is_anomaly)})\n",
    "\n",
    "# Function to preprocess and extract features from a URL\n",
    "def extract_features(url):\n",
    "    # Your feature extraction code here\n",
    "    pass\n",
    "\n",
    "# Function to store output in a database\n",
    "def store_in_database(url, is_anomaly):\n",
    "    # Your database storage code here\n",
    "    pass\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "from mlmodel import isolation_forest  # Import the trained model from mlmodel.py\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Endpoint to handle URL requests\n",
    "@app.route('/detect-malicious-url', methods=['POST'])\n",
    "def detect_malicious_url():\n",
    "    # Get URL from request\n",
    "    url = request.json.get('url')\n",
    "\n",
    "    # Predict using the ML model\n",
    "    is_anomaly = isolation_forest.predict([url])[0]\n",
    "\n",
    "    # Return result to front-end\n",
    "    return jsonify({'is_malicious': bool(is_anomaly)})\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify, render_template\n",
    "from mlmodel import detect_malicious_url  # Import the function from your ML model file\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Route to serve the homepage HTML file\n",
    "@app.route('/')\n",
    "def home():\n",
    "    return render_template('homepage.html')\n",
    "\n",
    "# Route to handle requests from the frontend form\n",
    "@app.route('/detect-malicious-url', methods=['POST'])\n",
    "def detect_malicious_url():\n",
    "    # Get URL input from the HTML form\n",
    "    url = request.form.get('url')\n",
    "\n",
    "    # Invoke the ML model function to make a prediction\n",
    "    is_malicious = detect_malicious_url(url)\n",
    "\n",
    "    # Return the prediction result to the frontend\n",
    "    return jsonify({'is_malicious': is_malicious})\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from flask import Flask, request, jsonify\n",
    "from mlmodel import isolation_forest  # Import the trained model from mlmodel.py\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Endpoint to handle URL requests\n",
    "@app.route('/detect-malicious-url', methods=['POST'])\n",
    "def detect_malicious_url():\n",
    "    # Get URL from request\n",
    "    url = request.json.get('url')\n",
    "\n",
    "    # Predict using the ML model\n",
    "    is_anomaly = isolation_forest.predict([url])[0]\n",
    "\n",
    "    # Return result to front-end\n",
    "    return jsonify({'is_malicious': bool(is_anomaly)})\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "from mlmodel import isolation_forest  # Import the trained model from mlmodel.py\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Endpoint to handle URL requests\n",
    "@app.route('/detect-malicious-url', methods=['POST'])\n",
    "def detect_malicious_url():\n",
    "    # Get URL from request\n",
    "    url = request.json.get('url')\n",
    "\n",
    "    # Predict using the ML model\n",
    "    is_anomaly = isolation_forest.predict([url])[0]\n",
    "\n",
    "    # Return result to front-end\n",
    "    return jsonify({'is_malicious': bool(is_anomaly)})\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
