{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "USING ANOMALY DETECTION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of anomalies detected: 12617\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Loading the dataset\n",
    "dataset = pd.read_csv('D:/Education/PYTHON/ML-v2/Datasets/malicious_phish.csv')\n",
    "\n",
    "# Extracting domain-based features\n",
    "dataset['domain_length'] = dataset['url'].apply(lambda x: len(re.findall('/.', x)))\n",
    "dataset['subdomains'] = dataset['url'].apply(lambda x: x.count('.') - 1)\n",
    "dataset['has_ip'] = dataset['url'].apply(lambda x: 1 if re.match(r'\\b\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\b', x) else 0)\n",
    "\n",
    "# Extracting path-based features\n",
    "dataset['path_length'] = dataset['url'].apply(lambda x: len(re.findall('/', x)))\n",
    "dataset['path_depth'] = dataset['url'].apply(lambda x: x.count('/'))\n",
    "\n",
    "# Extracting character-based features\n",
    "special_characters = '@/%/$/=/./_/?/:/~/'\n",
    "dataset['special_chars_count'] = dataset['url'].apply(lambda x: sum(x.count(char) for char in special_characters))\n",
    "\n",
    "# Combine features\n",
    "X = dataset[['domain_length', 'subdomains', 'has_ip', 'path_length', 'path_depth', 'special_chars_count']].values\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "X_train, X_test = train_test_split(X, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the Isolation Forest model\n",
    "isolation_forest = IsolationForest(contamination=0.1, random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "isolation_forest.fit(X_train)\n",
    "\n",
    "# Predictions on the testing set\n",
    "y_pred = isolation_forest.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "print(\"Number of anomalies detected:\", len(y_pred[y_pred == -1]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The (extract_features function) preprocesses the new URL and extracts the same features used in training the model.\n",
    "2. The features extracted from the new URL are transformed into a numpy array with the same shape as the training data.\n",
    "3. The Isolation Forest model predicts whether the new URL is an anomaly (-1) or not (1).\n",
    "4. Based on the prediction, it prints whether the URL is detected as an anomaly or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The URL is detected as an anomaly.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "\n",
    "# Function to preprocess and extract features from a URL\n",
    "def extract_features(url):\n",
    "    domain_length = len(re.findall('/.', url))\n",
    "    subdomains = url.count('.') - 1\n",
    "    has_ip = 1 if re.match(r'\\b\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\b', url) else 0\n",
    "    path_length = len(re.findall('/', url))\n",
    "    path_depth = url.count('/')\n",
    "    special_characters = '@/%/$/=/./_/?/:/~/'\n",
    "    special_chars_count = sum(url.count(char) for char in special_characters)\n",
    "    \n",
    "    return [domain_length, subdomains, has_ip, path_length, path_depth, special_chars_count]\n",
    "\n",
    "# URL to test\n",
    "new_url = \"https://l.wl.co/l?u=https://t.co/P5vuMF1nNo?fbclid=SavannahThomas_%F0%9D%95%80_%F0%9D%94%B8%F0%9D%95%84_%F0%9D%94%B8_%F0%9D%95%8A%F0%9D%95%80%E2%84%95%F0%9D%94%BE%F0%9D%95%83%F0%9D%94%BC_%F0%9D%95%8E%F0%9D%95%86%F0%9D%95%84%F0%9D%94%B8%E2%84%95_%F0%9D%95%83%F0%9D%95%86%F0%9D%95%86%F0%9D%95%82%F0%9D%95%80%E2%84%95%F0%9D%94%BE_%F0%9D%94%BD%F0%9D%95%86%E2%84%9D_%F0%9D%94%B8_%F0%9D%95%84%F0%9D%95%80%F0%9D%94%BE%E2%84%8D%F0%9D%95%8B%F0%9D%95%90_%F0%9D%95%84%F0%9D%94%B8%E2%84%95_%F0%9D%95%80%E2%84%95_%F0%9D%95%84%F0%9D%95%90_%F0%9D%94%B9%F0%9D%94%BC%F0%9D%94%BB%E2%84%9D%F0%9D%95%86%F0%9D%95%86%F0%9D%95%84_%F0%9D%95%80_%F0%9D%95%8E%F0%9D%94%B8%F0%9D%95%80%F0%9D%95%8B_%F0%9D%94%BD%F0%9D%95%86%E2%84%9D_%F0%9D%95%90%F0%9D%95%86%F0%9D%95%8C_%F0%9D%95%80%E2%84%95_%F0%9D%94%B8_%E2%84%82%F0%9D%95%83%F0%9D%95%86%F0%9D%95%8A%F0%9D%94%BC%F0%9D%94%BB_%E2%84%9D%F0%9D%95%86%F0%9D%95%86%F0%9D%95%84\"\n",
    "\n",
    "# Extract features from the new URL\n",
    "new_url_features = extract_features(new_url)\n",
    "\n",
    "# Transform features into the same format as the training data\n",
    "new_url_features_array = np.array(new_url_features).reshape(1, -1)\n",
    "\n",
    "# Predict anomaly\n",
    "is_anomaly = isolation_forest.predict(new_url_features_array)\n",
    "\n",
    "if is_anomaly == -1:\n",
    "    print(\"The URL is detected as an anomaly.\")\n",
    "else:\n",
    "    print(\"The URL is not detected as an anomaly.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'anomaly_detection_plot.html'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import IsolationForest\n",
    "import plotly.graph_objs as go\n",
    "import plotly.offline as py\n",
    "\n",
    "# Loading the dataset\n",
    "dataset = pd.read_csv('D:/Education/PYTHON/ML-v2/Datasets/malicious_phish.csv')\n",
    "\n",
    "#FEATURE EXTRACTION\n",
    "# Extracting domain-based features\n",
    "dataset['domain_length'] = dataset['url'].apply(lambda x: len(re.findall('/.', x)))\n",
    "dataset['subdomains'] = dataset['url'].apply(lambda x: x.count('.') - 1)\n",
    "dataset['has_ip'] = dataset['url'].apply(lambda x: 1 if re.match(r'\\b\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\b', x) else 0)\n",
    "\n",
    "# Extracting path-based features\n",
    "dataset['path_length'] = dataset['url'].apply(lambda x: len(re.findall('/', x)))\n",
    "dataset['path_depth'] = dataset['url'].apply(lambda x: x.count('/'))\n",
    "\n",
    "# Extracting character-based features\n",
    "special_characters = '@/%/$/=/./_/?/:/~/'\n",
    "dataset['special_chars_count'] = dataset['url'].apply(lambda x: sum(x.count(char) for char in special_characters))\n",
    "\n",
    "# Combine features (Combines all the extracted features into a single NumPy array X)\n",
    "X = dataset[['domain_length', 'subdomains', 'has_ip', 'path_length', 'path_depth', 'special_chars_count']].values\n",
    "\n",
    "# Initialize the Isolation Forest model\n",
    "isolation_forest = IsolationForest(contamination=0.1, random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "isolation_forest.fit(X)\n",
    "\n",
    "# Predictions on the dataset\n",
    "y_pred = isolation_forest.predict(X)\n",
    "\n",
    "# Convert predictions to a boolean array indicating anomalies (True) and inliers (False)\n",
    "anomalies = y_pred == -1\n",
    "\n",
    "# Filter X_train based on anomalies\n",
    "X_train_anomalies = X[anomalies]\n",
    "\n",
    "# Create a scatter plot of the dataset\n",
    "scatter = go.Scatter(x=X[:, 0], y=X[:, 1], mode='markers', \n",
    "                     marker=dict(color='blue', opacity=0.5), \n",
    "                     name='Inliers')\n",
    "\n",
    "# Create a scatter plot of anomalies\n",
    "anomaly_scatter = go.Scatter(x=X_train_anomalies[:, 0], y=X_train_anomalies[:, 1], mode='markers', \n",
    "                             marker=dict(color='red', opacity=0.5), \n",
    "                             name='Anomalies')\n",
    "\n",
    "# Layout settings\n",
    "layout = go.Layout(title='Anomaly Detection with Isolation Forest', \n",
    "                   xaxis=dict(title='Feature 1'), yaxis=dict(title='Feature 2'))\n",
    "\n",
    "# Create figure\n",
    "fig = go.Figure(data=[scatter, anomaly_scatter], layout=layout)\n",
    "\n",
    "# Save the plot as HTML file\n",
    "py.plot(fig, filename='anomaly_detection_plot.html')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
