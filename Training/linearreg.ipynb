{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LINEAR REGRESSION DETECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7830219826626433\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.89      0.84     85778\n",
      "           1       0.73      0.58      0.64     44461\n",
      "\n",
      "    accuracy                           0.78    130239\n",
      "   macro avg       0.77      0.73      0.74    130239\n",
      "weighted avg       0.78      0.78      0.78    130239\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Loading the dataset\n",
    "dataset = pd.read_csv('D:/Education/PYTHON/ML-v2/Datasets/malicious_phish.csv')\n",
    "\n",
    "# Extracting domain-based features\n",
    "dataset['domain_length'] = dataset['url'].apply(lambda x: len(re.findall('/.', x)))\n",
    "dataset['subdomains'] = dataset['url'].apply(lambda x: x.count('.') - 1)\n",
    "dataset['has_ip'] = dataset['url'].apply(lambda x: 1 if re.match(r'\\b\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\b', x) else 0)\n",
    "\n",
    "# Extracting path-based features\n",
    "dataset['path_length'] = dataset['url'].apply(lambda x: len(re.findall('/', x)))\n",
    "dataset['path_depth'] = dataset['url'].apply(lambda x: x.count('/'))\n",
    "\n",
    "# Extracting character-based features\n",
    "special_characters = '@/%/$/=/./_/?/:/~/'\n",
    "dataset['special_chars_count'] = dataset['url'].apply(lambda x: sum(x.count(char) for char in special_characters))\n",
    "\n",
    "# Encoding labels to numerical format\n",
    "label_mapping = {'benign': 0, 'defacement': 1, 'phishing': 1, 'malware': 1}\n",
    "dataset['type'] = dataset['type'].map(label_mapping)\n",
    "\n",
    "# Combine features\n",
    "X = dataset[['domain_length', 'subdomains', 'has_ip', 'path_length', 'path_depth', 'special_chars_count']].values\n",
    "y = dataset['type'].values\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the Logistic Regression model\n",
    "logistic_regression = LogisticRegression()\n",
    "\n",
    "# Fit the model\n",
    "logistic_regression.fit(X_train, y_train)\n",
    "\n",
    "# Predictions on the testing set\n",
    "y_pred = logistic_regression.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "print(\"Accuracy:\", logistic_regression.score(X_test, y_test))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Encoded the labels to numerical format, where 0 represents benign URLs and 1 represents malicious URLs (combining defacement, phishing, and malware).\n",
    "2. Using logistic regression, which is suitable for binary classification tasks, to predict whether a URL is malicious or not based on its features.\n",
    "3. The model is trained and evaluated using the training and testing sets, respectively.\n",
    "4. Evaluation is performed using accuracy and classification report metrics, including precision, recall, and F1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The URL is classified as malicious.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "\n",
    "# Function to preprocess and extract features from a URL\n",
    "def extract_features(url):\n",
    "    domain_length = len(re.findall('/.', url))\n",
    "    subdomains = url.count('.') - 1\n",
    "    has_ip = 1 if re.match(r'\\b\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\b', url) else 0\n",
    "    path_length = len(re.findall('/', url))\n",
    "    path_depth = url.count('/')\n",
    "    special_characters = '@/%/$/=/./_/?/:/~/'\n",
    "    special_chars_count = sum(url.count(char) for char in special_characters)\n",
    "    \n",
    "    return [domain_length, subdomains, has_ip, path_length, path_depth, special_chars_count]\n",
    "\n",
    "# URL to test\n",
    "new_url = \"https://www.kaspersky.co.in/\"\n",
    "\n",
    "# Extract features from the new URL\n",
    "new_url_features = extract_features(new_url)\n",
    "\n",
    "# Transform features into a numpy array with the same shape as the training data\n",
    "new_url_features_array = np.array(new_url_features).reshape(1, -1)\n",
    "\n",
    "# Predict whether the URL is malicious or benign\n",
    "prediction = logistic_regression.predict(new_url_features_array)\n",
    "\n",
    "if prediction == 0:\n",
    "    print(\"The URL is classified as benign.\")\n",
    "else:\n",
    "    print(\"The URL is classified as malicious.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
